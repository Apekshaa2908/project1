# -*- coding: utf-8 -*-
"""Redshift SQL Query.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NDEHW8H-U6yCMiJX-d8DKIVyychQrthe
"""

REATE DATABASE news_events_db;


SELECT current_database();


use news_events_db;
-- Drop dependent table first (news_events_data) due to FK constraints
DROP TABLE IF EXISTS news_events_data CASCADE;

-- Drop referenced table next
DROP TABLE IF EXISTS news_events_included CASCADE;

DROP VIEW IF EXISTS news_events_tableau_view CASCADE;


-- ============================
-- 1️⃣ Create Main Data Table
-- ============================
CREATE TABLE IF NOT EXISTS public.news_events_data (
    event_id TEXT PRIMARY KEY,
    summary VARCHAR(65535),
    category VARCHAR(65535),
    found_at TEXT,
    confidence REAL,
    article_sentence VARCHAR(65535),
    location VARCHAR(65535),
    award VARCHAR(65535),
    effective_date TEXT,
    product VARCHAR(65535),
    company_id TEXT,
    source_id TEXT
);

-- ============================
-- 2️⃣ Create Included Table
-- ============================
CREATE TABLE IF NOT EXISTS public.news_events_included (
    included_id TEXT,
    type VARCHAR(65535),
    domain VARCHAR(65535),
    company_name VARCHAR(65535),
    ticker VARCHAR(65535),
    author VARCHAR(65535),
    image_url VARCHAR(65535),
    url VARCHAR(65535),
    published_at TEXT
);

-- ============================
-- 3️⃣ Create Data Quality Summary Table
-- ============================
CREATE TABLE IF NOT EXISTS public.dq_summary (
    dq_id BIGINT IDENTITY(1,1),
    run_id VARCHAR(100),
    table_name VARCHAR(200),
    dq_dimension VARCHAR(200),
    dq_metric VARCHAR(200),
    dq_value FLOAT,
    dq_status VARCHAR(20),
    dq_check_time TIMESTAMP DEFAULT GETDATE()
);

DROP VIEW IF EXISTS public.vw_news_events_reporting;

CREATE VIEW public.vw_news_events_reporting AS
SELECT
    -- ===========================
    -- Core columns from news_events_data
    -- ===========================
    d.event_id,
    d.summary,
    d.category,
    d.found_at,
    d.confidence,
    d.article_sentence,
    d.location,
    d.award,
    d.effective_date,
    d.product,
    d.company_id,
    d.source_id,

    -- ===========================
    -- Core columns from news_events_included
    -- ===========================
    i.included_id,
    i.type AS included_type,
    i.domain AS source_domain,
    i.company_name,
    i.ticker,
    i.author,
    i.image_url,
    i.url AS included_url,
    i.published_at AS included_published_at,

    -- ===========================
    -- Derived helper columns for Tableau
    -- ===========================
    TRY_CAST(d.confidence AS DOUBLE PRECISION) AS confidence_value,

    TRY_CAST(SPLIT_PART(d.effective_date, ' ', 1) AS DATE) AS effective_date_parsed,

    CASE
      WHEN TRY_CAST(SPLIT_PART(d.effective_date, ' ', 1) AS DATE) IS NOT NULL
      THEN DATEDIFF('day', TRY_CAST(SPLIT_PART(d.effective_date, ' ', 1) AS DATE), CURRENT_DATE)
      ELSE NULL
    END AS effective_age_days,

    CASE
      WHEN TRY_CAST(SPLIT_PART(d.effective_date, ' ', 1) AS DATE) IS NULL THEN 'Invalid Date'
      WHEN DATEDIFF('day', TRY_CAST(SPLIT_PART(d.effective_date, ' ', 1) AS DATE), CURRENT_DATE) <= 7 THEN 'Fresh (≤7 days)'
      WHEN DATEDIFF('day', TRY_CAST(SPLIT_PART(d.effective_date, ' ', 1) AS DATE), CURRENT_DATE) <= 30 THEN 'Recent (≤30 days)'
      ELSE 'Stale (>30 days)'
    END AS freshness_category

FROM public.news_events_data d
LEFT JOIN public.news_events_included i
  ON d.company_id = i.included_id
  OR d.source_id = i.included_id;